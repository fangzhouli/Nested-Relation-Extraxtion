{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "sys.path.append(\"../py\")\n",
    "sys.path.append(\"../lib/BioInfer_software_1.0.1_Python3/\")\n",
    "\n",
    "from bioinferdataset import BioInferDataset\n",
    "from config import *\n",
    "from INN import INNModelLightning\n",
    "\n",
    "\n",
    "def update_batch_S(new_batch, batch):\n",
    "    S = batch[0][\"S\"]\n",
    "    for i in range(1, len(batch)):\n",
    "        s_new = batch[i][\"S\"]\n",
    "        s_new[s_new > -1] += batch[i - 1][\"T\"].shape[0]\n",
    "        S = torch.cat([S, s_new])\n",
    "    new_batch[\"S\"] = S\n",
    "    return new_batch\n",
    "\n",
    "\n",
    "def collate_list_keys(new_batch, batch, list_keys):\n",
    "    for key in list_keys:\n",
    "        new_batch[key] = [sample[key] for sample in batch]\n",
    "    return new_batch\n",
    "\n",
    "\n",
    "def collate_cat_keys(new_batch, batch, cat_keys):\n",
    "    for key in cat_keys:\n",
    "        new_batch[key] = torch.cat([sample[key] for sample in batch])\n",
    "    return new_batch\n",
    "\n",
    "\n",
    "def collate_func(batch):\n",
    "    cat_keys = [\"element_names\", \"L\", \"labels\", \"is_entity\", \"L\"]\n",
    "    list_keys = [\"tokens\", \"entity_spans\"]\n",
    "\n",
    "    if type(batch) == dict:\n",
    "        batch = [batch]\n",
    "\n",
    "    new_batch = {}\n",
    "    new_batch = collate_list_keys(new_batch, batch, list_keys)\n",
    "    new_batch = collate_cat_keys(new_batch, batch, cat_keys)\n",
    "    new_batch = update_batch_S(new_batch, batch)\n",
    "\n",
    "    T = torch.arange(len(new_batch[\"element_names\"]))\n",
    "    new_batch[\"T\"] = T\n",
    "\n",
    "    return new_batch\n",
    "\n",
    "\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(\"Running on the GPU\")\n",
    "        GPUS = 1\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Running on the CPU\")\n",
    "        GPUS = 0\n",
    "    return GPUS\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    dataset = BioInferDataset(XML_PATH)\n",
    "    if os.path.isfile(PREPPED_DATA_PATH):\n",
    "        dataset.load_samples_from_pickle(PREPPED_DATA_PATH)\n",
    "    else:\n",
    "        dataset.prep_data()\n",
    "        dataset.samples_to_pickle(PREPPED_DATA_PATH)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def split_data(dataset):\n",
    "    train_max_range = round(0.8 * len(dataset))\n",
    "    train_idx = range(0, train_max_range)\n",
    "    val_idx = range(train_max_range, len(dataset))\n",
    "    train_set, val_set = random_split(dataset, lengths=[len(train_idx), len(val_idx)])\n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "\n",
    "GPUS = set_device()\n",
    "dataset = load_dataset()\n",
    "train_set, val_set = split_data(dataset)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_set, collate_fn=collate_func, batch_size=BATCH_SIZE\n",
    ")\n",
    "val_data_loader = DataLoader(val_set, collate_fn=collate_func, batch_size=1)\n",
    "\n",
    "model = INNModelLightning(\n",
    "    vocab_dict=dataset.vocab_dict,\n",
    "    element_to_idx=dataset.element_to_idx,\n",
    "    word_embedding_dim=WORD_EMBEDDING_DIM,\n",
    "    cell_state_clamp_val=CELL_STATE_CLAMP_VAL,\n",
    "    hidden_state_clamp_val=HIDDEN_STATE_CLAMP_VAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INNModelLightning(\n",
       "  (cell): DAGLSTMCell(\n",
       "    (W_ioc_hat): Linear(in_features=512, out_features=1536, bias=False)\n",
       "    (U_ioc_hat): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "    (W_fs): Linear(in_features=512, out_features=1024, bias=False)\n",
       "    (U_fs): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "  )\n",
       "  (inn): INNModel(\n",
       "    (word_embeddings): Embedding(5200, 256)\n",
       "    (element_embeddings): Embedding(132, 512)\n",
       "    (attn_scores): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (blstm): LSTM(256, 256, bidirectional=True)\n",
       "    (cell): DAGLSTMCell(\n",
       "      (W_ioc_hat): Linear(in_features=512, out_features=1536, bias=False)\n",
       "      (U_ioc_hat): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "      (W_fs): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (U_fs): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    )\n",
       "    (output_linear): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dot.svg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = make_dot(x, params=dict(model.named_parameters()))\n",
    "dot.render('./dot',format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
